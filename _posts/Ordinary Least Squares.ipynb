{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ordinary Least Squares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Today, in this blog post, I will talk about a very useful regression method: Ordinary Least Squares. It is frequently used in economics, statistics, and data science. It is simple to use, but it is also the foundation of some of the more advanced regression methods. So you may ask: what is ordinary least squares? What is a regression? And why am I learning this? What am I gonna use it for? Just bear with me, and I will provide examples of why regressions are very useful in today’s world. And keep in mind, because this blog is just an elementary introduction for ordinary least squares, so I will not dive into the difficult math equations to prove its assumptions and merits. Nor will I go over specific codes to calculate it. It is beyond the scope of this blog. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is regression analysis?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK. First, what is regression analysis? What is it for?      \n",
    "\n",
    "Wikipedia gives a very technical definition:      \n",
    "\n",
    "\"*regression analysis is a set of statistical processes for estimating the relationships among variables. It includes many techniques for modeling and analyzing several variables, when the focus is on the relationship between a dependent variable and one or more independent variables (or 'predictors')*\"$^1$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is very hard to understand, isn’t? Let’s see an example. We often see in crime/detective movies, when the detectives see the footprints of a suspect, they can instantly tell roughly how tall the suspect is. How did they do that? Is that some kind of magic? Of course not! They know that because there is a relationship between a person’s height and foot size. According to a study by the University of Rhode Island Department of Electrical, Computer and Biomedical Engineering, the normal height-to-foot ratio is about 6.6:1$^2$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In layman's terms, regression analysis is a method to study the relationship between variables. It can be the relationship between a person’s height and foot size (like the example above), or the relationship between the amount of sun light and corn production, or the relationship between the amount of cheese your mom put in your mac & cheese and how delicious it is. Just like people are connected with different relationships, variables can also be connected with certain relationships. Regression analysis helps us discover these relationships. It identifies one variable as a dependent variable, and other one or more variables as independent variables. Then it studies how the change of independent variables will affect the dependent variable. The relationships between dependent variables and independent variables help us better understand the world. Ordinary least squares (or OLS in short) is a way to discover this kind of relationship."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is OLS?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s go back to Wikipedia, and find the technical definition:  \n",
    "\n",
    "“*In statistics, ordinary least squares (OLS) is a type of linear least squares method for estimating the unknown parameters in a linear regression model. OLS chooses the parameters of a linear function of a set of explanatory variables by the principle of least squares: minimizing the sum of the squares of the differences between the observed dependent variable (values of the variable being predicted) in the given dataset and those predicted by the linear function*”$^3$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, very hard to understand! But there are a few key words of OLS we should notice.     \n",
    "\n",
    "### 1. Linear\n",
    "\n",
    "For OLS to work properly, the relationship between a dependent variable and independent variables must be linear. Below is an example of a linear relationship$^4$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](linear.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Source](http://www.360doc.com/content/18/0706/10/15930282_768242401.shtml)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the relationship is quadratic or in other forms, then we cannot use OLS. It would do a bad job estimating the relationship. Below is an example of a quadratic relationship$^5$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](quadratics.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Source](http://mathcentral.uregina.ca/QQ/database/QQ.09.06/mike1.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see an example of an OLS function: \n",
    "$$y=\\beta_0+\\beta_1x$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does that look familiar? I think most of you have encountered such a function during high school. I guess back then, you did a lot of calculations to figure out the slopes and the intercepts of this kind of functions.  And this is what we are doing now! OLS is just a more complicated way to figure out the slopes and the intercepts. Behind this equation, mathematicians did a lot of hard work to figure out how OLS works to calculate $\\beta_0$ and $\\beta_1$, and they also proved that why OLS does a very good job estimating $\\beta_0$ and $\\beta_1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Minimizing the sum of the squares of the differences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now is the hard part.     \n",
    "\n",
    "First, the differences. What differences?     \n",
    "\n",
    "Let’s go back to the linear graph again$^4$. We can see in the graph that there is a line $f(x_i)$ almost simulates the pattern of $y_1, y_2, …, y_5$, but each $y_i$ is not on the line. Here, the $\\{y_i\\}$ represents the true values, values that you get from a dataset. And the line $f(x_i)$ is the predicted value of $\\{y_i\\}$. It is a line you draw that you think it represents the relationship between $x_i$ and $y_i$. But how do we know this line is good? What does this line have to do with OLS?   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](difference.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Source](http://www.360doc.com/content/18/0706/10/15930282_768242401.shtml)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the differences are the differences between each $y_i$ and each $f(x_i)$, namely, the differences between each true value and each predicted value. To check how accurately each $f(x_i)$ predicts each $y_i$, we need to sum up all the differences. But some of the $y_i$ is larger than $f(x_i)$, some smaller. The positive and negative differences may cancel each other out. What shall we do now? To solve this problem, OLS first squares the differences, and then sums up the squared differences together. In this way, there are no negative differences to affect our analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This sum of differences can be expressed as:\n",
    "$$\\sum (\\beta_0+\\beta_1x_i-y_i)^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then what does OLS do? OLS finds the $\\beta_0$ and $\\beta_1$ that minimize this function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sounds simple, right? But the math calculations behind it are not simple at all. It is very difficult for people to calculate the answers by hand. Fortunately, now we have a lot of computer software programs to do the math for us, such as Stata, Matlab, Python, and R. The calculations are beyond the scope of this introductory blog post and anyone interested can search for answers themselves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Today we introduced a regression method called ordinary least squares. It finds the $\\beta_0$ and $\\beta_1$ that can minimize the function:   \n",
    "\n",
    "$$\\sum (\\beta_0+\\beta_1x_i-y_i)^2$$\n",
    "\n",
    "It looks easy, right? So does it really do a good job estimating the relationship between $x_i$ and $y_i$? \n",
    "\n",
    "Yes, of course!    \n",
    "1. The estimator $\\beta_0$ and $\\beta_1$ are unbiased.\n",
    "2. $\\beta_0$ and $\\beta_1$ are consistent.\n",
    "3. $\\beta_0$ and $\\beta_1$ are asymptotically normal.    \n",
    "\n",
    "Now you may wonder what unbiased, consistent, and asymptotically normal mean. I will definitely explain those in my next blog post. In short, the above means that $\\beta_0$ and $\\beta_1$ calculated by OLS are almost “equal” to the true value.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then you may ask: if OLS is so powerful, can I use it under any condition? \n",
    "\n",
    "NO!    \n",
    "\n",
    "Even though OLS is powerful, it also has its limitations. We will discuss these more in the next blog post as well.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you learned what regression analysis is, go and try it for yourself and see what questions or problems you have, and we can discuss those next time. Or you can just go and tell your friend, you know how tall he or she is, by simply measuring his or her foot size! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sources:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Regression analysis. Wikipedia. (n.d.). Retrieved from https://en.wikipedia.org/wiki/Regression_analysis  \n",
    "2. Tremblay, S. Height-to-Foot-Size Ratio. (n.d.). Retrived from https://www.livestrong.com/article/491821-height-to-foot-size-ratio/\n",
    "3. Ordinary least squares. Wikipedia. (n.d.). Retrieved from https://en.wikipedia.org/wiki/Ordinary_least_squares\n",
    "4. Fengjiutian88. How to understand OLS? (2018). Retrieved from http://www.360doc.com/content/18/0706/10/15930282_768242401.shtml \n",
    "5. Penny. Graphing quadratic equations. (n.d.). Retrieved from http://mathcentral.uregina.ca/QQ/database/QQ.09.06/mike1.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
